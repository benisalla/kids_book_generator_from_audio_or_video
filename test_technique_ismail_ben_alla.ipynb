{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I2gIzt3qY1D"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pytube\n",
        "!pip install assemblyai\n",
        "!pip install --upgrade pytube\n",
        "!pip install yt-dlp\n",
        "!pip install openai\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "ZXZAMhPIM4t2"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "import os\n",
        "import assemblyai as aai\n",
        "from assemblyai.types import TranscriptionConfig\n",
        "import yt_dlp\n",
        "from openai import OpenAI\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "RaS8gIKIMsn9"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Env Var"
      ],
      "metadata": {
        "id": "QugkV78GMs8x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "f3HZ22klqY1G"
      },
      "outputs": [],
      "source": [
        "# URL de la vidÃ©o Ã  illustrer\n",
        "URL = \"https://youtu.be/FZGHtLw4ZPY\"\n",
        "dir_path = \"./\"\n",
        "audio_file_name = \"audio.webm\"\n",
        "audio_txt_path = \"/content/audio.txt\"\n",
        "audio_json_path = \"/content/audio.json\"\n",
        "audio_file_path = os.path.join(dir_path, audio_file_name)\n",
        "\n",
        "# img\n",
        "IMG_MODEL_TYPE = \"dall-e-3\" # \"dall-e-2\"\n",
        "IMG_SIZE = \"1024x1024\"\n",
        "IMG_QUALITY = \"standard\"    # hd\n",
        "IMG_DIR = \"images\"\n",
        "IMG_EXTENTION = \"png\"       # jpg\n",
        "img_json_path = \"img_url.json\"\n",
        "\n",
        "# prompts and model config\n",
        "EXTRACT_PROMPT = \"\"\"\n",
        "You are an expert in analyzing text to identify sections that can be illustrated with images, especially for children.\n",
        "Your task is to carefully process a piece of text written in French and provide concise, kid-friendly prompts for each image to be generated.\n",
        "\n",
        "Here are the guidelines you must strictly follow:\n",
        "* Analyze the provided French text and identify meaningful portions that can be illustrated.\n",
        "* For each identified portion, generate a concise and descriptive prompt in English that describes a vivid and kid-friendly scene.\n",
        "* Ensure the prompts are specifically designed to generate images that are visually appealing to children.\n",
        "* The output must be a JSON object where:\n",
        "  - Each key is a portion of the original French text.\n",
        "  - Each value is the corresponding image-generation prompt in English.\n",
        "* The response **must be strictly in JSON format**, with no additional text, explanations, or formatting outside the JSON structure.\n",
        "* If the text has no identifiable portions suitable for illustration, return an empty JSON object: `{}`.\n",
        "* The JSON format must adhere to this structure:\n",
        "  ```json\n",
        "  {\n",
        "      \"portion of the original text here\": \"the prompt to generate a nice illustration of the scene for kids\",\n",
        "      ...\n",
        "  }\n",
        "\"\"\"\n",
        "MODEL_TYPE = \"gpt-4o\"\n",
        "\n",
        "# api keys\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "AAI_API_KEY = str(os.getenv(\"AAI_API_KEY\"))\n",
        "OPENAI_API_KEY = str(os.getenv(\"OPENAI_API_KEY\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVhtMw6ZqY1K"
      },
      "source": [
        "#  1. Download the audio from the video"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I modified the original code I received because I couldn't resolve some issues and didn't have enough time to focus on them, so I opted for another approach to"
      ],
      "metadata": {
        "id": "_6aGWnLntxEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download audio\n",
        "ydl_opts = {\n",
        "    \"format\": \"bestaudio/best\",\n",
        "    \"outtmpl\": f\"{dir_path}audio.%(ext)s\",\n",
        "}\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([URL])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY2V_SGLOwbN",
        "outputId": "14600ce2-e599-4e6f-bfb7-26daf6f5c3d1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/FZGHtLw4ZPY\n",
            "[youtube] FZGHtLw4ZPY: Downloading webpage\n",
            "[youtube] FZGHtLw4ZPY: Downloading ios player API JSON\n",
            "[youtube] FZGHtLw4ZPY: Downloading mweb player API JSON\n",
            "[youtube] FZGHtLw4ZPY: Downloading m3u8 information\n",
            "[info] FZGHtLw4ZPY: Downloading 1 format(s): 251\n",
            "[download] ./audio.webm has already been downloaded\n",
            "[download] 100% of    3.35MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOIc9P5YqY1L"
      },
      "source": [
        "# 2. Transcription de l'audio (Speech to text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I commented out this code because I don't want to redo the transcription since I'm focusing on a single audio file ðŸ™‚, and I'm worried about running out of my API key credits."
      ],
      "metadata": {
        "id": "omdX21vgW2nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # API key\n",
        "# aai.settings.api_key = AAI_API_KEY\n",
        "\n",
        "# # init config\n",
        "# config = TranscriptionConfig(\n",
        "#     language_code=\"fr\",   # French\n",
        "#     punctuate=True,       # punctuation\n",
        "#     format_text=True,     # Format text\n",
        "# )\n",
        "\n",
        "# # init Transcriber\n",
        "# transcriber = aai.Transcriber(config=config)\n",
        "\n",
        "# try:\n",
        "#     # Transcribe\n",
        "#     transcript = transcriber.transcribe(audio_file_path)\n",
        "\n",
        "#     # Wait for the transcription to complete\n",
        "#     transcript.wait_for_completion()\n",
        "\n",
        "#     # Let's save the transcription (because we cannot afford re-doing it)\n",
        "#     with open(\"audio.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "#         file.write(transcript.text)\n",
        "\n",
        "#     print(\"Transcription saved to audio.txt!\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "FmusX2TeThaM"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5iOOyHKqY1N"
      },
      "source": [
        "# 3. Exploitation and Analysis of Transcription"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9nkqrfUqY1N"
      },
      "source": [
        "In the following section, we will focus on crafting an effective prompt to identify various sections of the text that can be illustrated with images.\n",
        "\n",
        "For now, our objective is to request GPT-4 to generate the most suitable prompt for creating each image. This will help ensure that the generated visuals align closely with the text's content and purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "85tmYPUzqY1O"
      },
      "outputs": [],
      "source": [
        "def generate_image_prompts(\n",
        "    text,\n",
        "    client,\n",
        "    model_type,\n",
        "    extract_prompt,\n",
        "    audio_json_path,\n",
        "    temperature=1,\n",
        "    max_tokens=1024,\n",
        "    top_p=1,\n",
        "    is_debug=False,\n",
        "):\n",
        "    # Call OpenAI API\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_type,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": extract_prompt\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Text: {text}\"\n",
        "            }\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        top_p=top_p,\n",
        "    )\n",
        "\n",
        "    # raw response from gpt\n",
        "    raw_response = response.choices[0].message.content\n",
        "\n",
        "    if is_debug:\n",
        "        print(\"Raw response from OpenAI API:\")\n",
        "        print(raw_response)\n",
        "\n",
        "    # let's use regex to extract json (we cannot blindly trust llms)\n",
        "    pattern = r\"```json\\s*(\\{[\\s\\S]*?\\})\\s*```\"\n",
        "    match = re.search(pattern, raw_response)\n",
        "\n",
        "    if match:\n",
        "        # If found, capture the JSON inside\n",
        "        raw_json_str = match.group(1)\n",
        "    else:\n",
        "        # Fallback pattern: look for any top-level curly-braced structure (could be wrong but let's do it)\n",
        "        fallback_pattern = r\"\\{[\\s\\S]*?\\}\"\n",
        "        fallback_match = re.search(fallback_pattern, raw_response)\n",
        "\n",
        "        if fallback_match:\n",
        "            raw_json_str = fallback_match.group(0)\n",
        "        else:\n",
        "            print(\"No valid JSON code block found in the response.\")\n",
        "\n",
        "    try:\n",
        "        # Attempt to parse the extracted string as JSON\n",
        "        json_data = json.loads(raw_json_str)\n",
        "\n",
        "        # Validate we got a dictionary\n",
        "        if not isinstance(json_data, dict):\n",
        "            raise ValueError(\"The response is not a valid JSON object.\")\n",
        "\n",
        "        # Validate that keys and values are strings\n",
        "        for key, value in json_data.items():\n",
        "            if not isinstance(key, str) or not isinstance(value, str):\n",
        "                raise ValueError(\"JSON keys and values must be strings.\")\n",
        "\n",
        "        # Save the validated JSON to a file\n",
        "        with open(audio_json_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            json.dump(json_data, file, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(f\"Validated JSON saved to {audio_json_path}\")\n",
        "\n",
        "    except (json.JSONDecodeError, ValueError) as e:\n",
        "        print(f\"Error: The response could not be processed as valid JSON. Details: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've commented out this section because it costs money to run it repeatedly, and I'm using a key with only $10, so I'm not sure how many times it allows me to experiment with different prompts and implementations of our helper function.\n",
        "\n",
        "Therefore, I could not experiment with different prompts, models, and configurations either."
      ],
      "metadata": {
        "id": "4xiX_qqDsVcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# # Read text from the file\n",
        "# with open(audio_txt_path, \"r\", encoding=\"utf-8\") as file:\n",
        "#     text = file.read()\n",
        "\n",
        "# # Generate image prompts\n",
        "# generate_image_prompts(\n",
        "#     text=text,\n",
        "#     client=client,\n",
        "#     model_type=MODEL_TYPE,\n",
        "#     extract_prompt=EXTRACT_PROMPT,\n",
        "#     audio_json_path=audio_json_path,\n",
        "#     temperature=1,\n",
        "#     max_tokens=1024,\n",
        "#     top_p=1,\n",
        "#     is_debug=True,\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgBWQ61M9Gte",
        "outputId": "92f4eebb-ab6b-48ca-9b2b-b6b8bb326840"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw response from OpenAI API:\n",
            "```json\n",
            "{\n",
            "    \"La grenouille Ã  grande bouche gobe des mouches avec sa grande bouche.\": \"A big-mouthed frog catching flies with its enormous mouth.\",\n",
            "    \"Elle vit dans une mare sur un Ã©nuphar qui lui sert de plongeoir.\": \"A big-mouthed frog sitting on a lily pad in a pond, ready to jump like on a diving board.\",\n",
            "    \"Au premier tournant, elle rencontre un ruban.\": \"The big-mouthed frog meeting an anteater with a long, sticky tongue like a ribbon.\",\n",
            "    \"D'un bon guirÃ©e, elle traverse une forÃªt.\": \"The big-mouthed frog hopping energetically through a lush, green forest.\",\n",
            "    \"T'es grande, toi ! T'es qui, toi ? Je suis une gira.\": \"The big-mouthed frog staring up at a tall giraffe.\",\n",
            "    \"Ã€ l'aide d'une canne, elle escala d'une montagne de mille kilogrammes.\": \"The big-mouthed frog climbing a very steep mountain with the help of a vine or stick.\",\n",
            "    \"T'es gros, toi ! T'es qui, toi ? Je suis le rhinocÃ©ros.\": \"The big-mouthed frog looking at a large, friendly rhinoceros.\",\n",
            "    \"Un peu plus tard, il se met Ã  pleuvoir.\": \"The scene of a rainforest starting to rain with a colorful toucan sitting on a branch.\",\n",
            "    \"Que t'es doux, toi. T'es qui, toi ? Je suis le tigre.\": \"The big-mouthed frog resting beside a gentle tiger with soft fur.\",\n",
            "    \"Mais de retour sur son Ã©nu fin, elle voit deux yeux dans la mare.\": \"The big-mouthed frog returning to her lily pad and spotting two mysterious eyes in the water.\",\n",
            "    \"Je suis le crocodile. Et tu manges quoi, toi? Des grenouilles Ã  grande bouche.\": \"A big crocodile emerging from the water, saying it eats big-mouthed frogs.\"\n",
            "}\n",
            "```\n",
            "Validated JSON saved to /content/audio.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'La grenouille Ã  grande bouche gobe des mouches avec sa grande bouche.': 'A big-mouthed frog catching flies with its enormous mouth.',\n",
              " 'Elle vit dans une mare sur un Ã©nuphar qui lui sert de plongeoir.': 'A big-mouthed frog sitting on a lily pad in a pond, ready to jump like on a diving board.',\n",
              " 'Au premier tournant, elle rencontre un ruban.': 'The big-mouthed frog meeting an anteater with a long, sticky tongue like a ribbon.',\n",
              " \"D'un bon guirÃ©e, elle traverse une forÃªt.\": 'The big-mouthed frog hopping energetically through a lush, green forest.',\n",
              " \"T'es grande, toi ! T'es qui, toi ? Je suis une gira.\": 'The big-mouthed frog staring up at a tall giraffe.',\n",
              " \"Ã€ l'aide d'une canne, elle escala d'une montagne de mille kilogrammes.\": 'The big-mouthed frog climbing a very steep mountain with the help of a vine or stick.',\n",
              " \"T'es gros, toi ! T'es qui, toi ? Je suis le rhinocÃ©ros.\": 'The big-mouthed frog looking at a large, friendly rhinoceros.',\n",
              " 'Un peu plus tard, il se met Ã  pleuvoir.': 'The scene of a rainforest starting to rain with a colorful toucan sitting on a branch.',\n",
              " \"Que t'es doux, toi. T'es qui, toi ? Je suis le tigre.\": 'The big-mouthed frog resting beside a gentle tiger with soft fur.',\n",
              " 'Mais de retour sur son Ã©nu fin, elle voit deux yeux dans la mare.': 'The big-mouthed frog returning to her lily pad and spotting two mysterious eyes in the water.',\n",
              " 'Je suis le crocodile. Et tu manges quoi, toi? Des grenouilles Ã  grande bouche.': 'A big crocodile emerging from the water, saying it eats big-mouthed frogs.'}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xmUvAKJqY1P"
      },
      "source": [
        "# 4. GÃ©nÃ©ration des illustrations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's generate images from the descriptions generated in the audio.json file using a model that generates images from text."
      ],
      "metadata": {
        "id": "ztdoJJQhGvdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's first create a diractory to store images\n",
        "!mkdir -p images"
      ],
      "metadata": {
        "id": "05L2HjCRrPuw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images_from_json(\n",
        "    json_data,\n",
        "    client,\n",
        "    model_type,\n",
        "    img_size,\n",
        "    img_quality,\n",
        "    img_dir,\n",
        "    img_json_path,\n",
        "    extention,\n",
        "    is_debug=False,\n",
        "):\n",
        "\n",
        "    # let's check if img_dir is created\n",
        "    if not os.path.exists(img_dir):\n",
        "        os.makedirs(img_dir, exist_ok=True)\n",
        "\n",
        "    if not isinstance(json_data, dict):\n",
        "        raise ValueError(\"JSON file must contain an object (key-value pairs).\")\n",
        "\n",
        "    # generating image for each prompt\n",
        "    json_result = {}\n",
        "    for key, prompt in json_data.items():\n",
        "        if not isinstance(prompt, str):\n",
        "            print(f\"Skipping {key}: Prompt is not a string.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Generating image for key: '{key}' with prompt: '{prompt}'...\")\n",
        "        try:\n",
        "            # Call to OpenAI Image Model\n",
        "            response = client.images.generate(\n",
        "                model=model_type,\n",
        "                prompt=prompt,\n",
        "                size=img_size,\n",
        "                quality=img_quality,\n",
        "                n=1\n",
        "            )\n",
        "\n",
        "            # url of the image\n",
        "            image_url = response.data[0].url\n",
        "            json_result[key] = {\n",
        "                \"prompt\": prompt,\n",
        "                \"url\": image_url\n",
        "            }\n",
        "\n",
        "            # download and save image in img_dir\n",
        "            image_filename = f\"{key}.{extention}\"\n",
        "            image_path = os.path.join(img_dir, image_filename)\n",
        "            img_data = requests.get(image_url).content\n",
        "\n",
        "            with open(image_path, \"wb\") as handler:\n",
        "                handler.write(img_data)\n",
        "\n",
        "            print(f\"Saved image to {image_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating image for key '{key}': {e}\")\n",
        "\n",
        "    # let's save {prompt: img_url}\n",
        "    with open(img_json_path, \"w\", encoding=\"utf-8\") as f_out:\n",
        "        json.dump(json_result, f_out, indent=4, ensure_ascii=False)\n",
        "    print(f\"Saved all generated image URLs to {img_json_path}\")"
      ],
      "metadata": {
        "id": "Bj7eRD3BW1vH"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have commented out this section because I can't afford to run it repeatedly ðŸ˜Š.\n",
        "\n",
        "For the same reason, I couldn't experiment with different manipulations of the prompts to make them align more closely with the subject. The images should be kid-friendly, more like paintings rather than realistic images, and perhaps the scene should be unified across all images and more...\n",
        "\n",
        "This is a very interesting project but it requires time and effort ðŸ™‚."
      ],
      "metadata": {
        "id": "ltCDXGinrKBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Init client\n",
        "# client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# # Load JSON\n",
        "# with open(audio_json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "#     json_data = json.load(f)\n",
        "\n",
        "# # just for test\n",
        "# json_data = dict(list(json_data.items())[:2])\n",
        "\n",
        "# # finally :) let's generate images\n",
        "# generate_images_from_json(\n",
        "#     json_data=json_data,\n",
        "#     client=client,\n",
        "#     model_type=IMG_MODEL_TYPE,\n",
        "#     img_size=IMG_SIZE,\n",
        "#     img_quality=IMG_QUALITY,\n",
        "#     img_dir=IMG_DIR,\n",
        "#     img_json_path=img_json_path,\n",
        "#     extention=IMG_EXTENTION,\n",
        "#     is_debug=True,\n",
        "# )"
      ],
      "metadata": {
        "id": "qc1MSkdaJq-C"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Tool Presentation with Perplexity"
      ],
      "metadata": {
        "id": "lxi5VBDgwfoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have created this section in a LaTeX document because books do not look appealing with too much text."
      ],
      "metadata": {
        "id": "bKoegpQuwpYZ"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test-technique-py310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_I2gIzt3qY1D",
        "QugkV78GMs8x",
        "tVhtMw6ZqY1K",
        "kOIc9P5YqY1L",
        "p5iOOyHKqY1N",
        "5xmUvAKJqY1P",
        "lxi5VBDgwfoh"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}